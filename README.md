# AIアシスタント

ユーザーの音声指示を理解し、適切なツールを使って生活をサポートするインテリジェントAIアシスタント

## ✨ 特徴

- **リアルタイム音声対話**: WebSocketベースの低遅延音声処理
- **処理状態表示**: 音声認識・理解・ツール実行の各段階をリアルタイム表示
- **AI+ルールベース応答**: 高速ルール処理とAIのハイブリッド応答システム
- **自然な会話スタイル**: 結論→補足の構造化された音声向け応答
- **AIモード切り替え**: スタンダードモード/全自動モードで動作を柔軟に制御
- **Gmail完全統合**: 音声コマンドでメール確認・返信・送信が可能（WHO/WHEN/WHAT形式）
- **カメラ画像認識**: OpenAI Vision APIで撮影した画像を分析・説明
- **性格タイプ分析**: 会話履歴から自動的にユーザーの性格を分析・可視化
- **アラーム機能**: 音声コマンドで時刻指定アラームを自動設定・管理
- **タスクテーブル**: 全自動モードの実行履歴を自動記録・管理
- **ハイブリッドLLM**: Claude API + OpenAI のマルチプロバイダー対応
- **個人情報管理**: ユーザー情報を記憶してパーソナライズ応答
- **高品質音声合成**: OpenAI TTSによる自然な日本語音声（1.2倍速で最適化）
- **モダンUI**: シンプルで洗練されたモノクロームデザイン
- **拡張可能なツールシステム**: モジュラー設計で機能追加が簡単

## 🏗️ アーキテクチャ

```
音声入力 → STT → ルールチェック → エージェントコア → ツール実行 → 応答生成 → TTS → 音声出力
              ↓       ↓              ↓                    ↓
    個人情報DB   AI処理        ツールレジストリ      履歴管理
```

## 🚀 セットアップ

### 1. 依存関係のインストール

```bash
# Python仮想環境の作成
python -m venv venv
source venv/bin/activate  # Windows: venv\\Scripts\\activate

# パッケージのインストール
pip install -r requirements.txt
```

### 2. 環境設定

```bash
# 設定ファイルをコピー
cp .env.example .env

# .envファイルを編集してAPIキーを設定
```

### 3. サーバーの起動

```bash
# 開発サーバー起動
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
```

## 🎯 使用方法

1. ブラウザで `http://localhost:8000` を開く
2. マイクの使用を許可
3. 「話しかけてね」が表示されたら画像をタップして話しかける
4. 個人情報を設定画面（☰）で登録（より個人に合った応答のため）
5. AIエージェントが応答し、必要に応じてツールを実行

### 設定画面の機能

設定画面（☰ ハンバーガーメニュー）からアクセスできる機能：

- **AIモデル設定**: Claude/ChatGPTの切り替え
- **ボイス設定**: 音声の選択（女性/男性/五条悟/初音ミク）
- **AIモード設定**: スタンダードモード/全自動モードの切り替え
- **利用可能なツール**: 連携済みツールの確認（Gmail/アラーム/カメラ認識など）
- **テーブル**: 全自動モードの実行履歴（処理中/完了）
- **連絡**: クイック連絡先（電話・ボイスメッセージ）
- **あなたの性格タイプ**: 会話から分析された性格診断
- **個人情報**: 名前・年齢・居住地・職業・趣味の登録

### 音声コマンド例

**ルールベース処理（高速応答）:**
- "おはよう" → 挨拶応答
- "今何時？" → 現在時刻
- "今日の日付は？" → 現在日付
- "10 + 5" → 計算結果
- "ありがとう" → "どういたしまして。ではまた後ほど。"
- "メール確認して" → Gmail一覧表示（最高優先度）
- "届いてるよって返信して" → Gmail返信実行（自動内容抽出）
- "明日の朝7時にアラームをセットして" → アラーム設定

**AI処理:**
- "今日の天気を教えて"
- "明日の予定をメモして"
- "プログラミングについて説明して"

## 📁 プロジェクト構造

```
voiceagent/
├── src/
│   ├── core/           # コアシステム（エージェント、ルール処理）
│   ├── audio/          # 音声処理（STT、TTS）
│   ├── llm/            # LLMインターフェース（Claude、OpenAI）
│   ├── memory/         # 記憶・学習システム
│   ├── tools/          # ツール実装（天気、計算、検索等）
│   └── main.py         # メインアプリケーション
├── templates/          # HTMLテンプレート
├── static/             # フロントエンド（CSS、JS）
├── data/               # データ保存（音声、メモリ）
└── tests/              # テスト
```

## 📧 Gmail連携機能

音声AIエージェントを通してGmailの内容確認、メール作成・送信が可能です。

### Gmail API設定

1. **Google Cloud Consoleでプロジェクト作成**
   - [Google Cloud Console](https://console.cloud.google.com/)にアクセス
   - 新しいプロジェクトを作成または既存プロジェクトを選択

2. **Gmail APIを有効化**
   ```bash
   # Gmail APIを検索して有効化
   # または直接リンク: https://console.cloud.google.com/apis/library/gmail.googleapis.com
   ```

3. **OAuth 2.0認証情報を作成**
   - 「認証情報」→「認証情報を作成」→「OAuth 2.0 クライアント ID」
   - アプリケーションタイプ：「デスクトップアプリケーション」
   - 作成後、JSONファイルをダウンロード

4. **認証ファイルを配置**
   ```bash
   # ダウンロードしたJSONファイルを以下に配置
   cp ~/Downloads/credentials.json data/gmail_credentials.json
   ```

5. **Gmail依存関係をインストール**
   ```bash
   pip install google-auth google-auth-oauthlib google-api-python-client
   ```

### Gmail使用例

**音声コマンド:**
- "未読メールを確認して" → メール一覧表示（WHO/WHEN/WHAT形式）
- "最新のメールを読んで" → 最新メール詳細読み取り
- "東京イノベーションベースからメール来てる？" → 送信者で検索（from:クエリ自動使用）
- "届いてるよって返信して" → メール返信（内容自動抽出）
- "了解しましたと返信" → 指定内容でメール返信
- "重要なメールをチェックして" → 重要マーク付きメール検索
- "〇〇さんにメールを送って、件名は△△、本文は□□" → メール送信

**利用可能な操作:**
- ✅ メール一覧取得（検索クエリ対応）
- ✅ 特定メールの詳細読み取り
- ✅ メール返信（高優先度ルール処理）
- ✅ メール送信
- ✅ 下書き作成

**🎯 Gmail音声応答の特徴:**
- **WHO（誰から）**: 送信者名を明確に伝える
- **WHEN（いつ）**: ローカルタイムゾーンで「今日の午後1時25分」のように相対時間表示
- **WHAT（内容）**: 本文を50文字以内に要約して簡潔に伝達
- **音声最適化**: 結論→補足の順で1-2文以内に応答
- **検索機能**: 「◯◯からメール来てる？」で自動的に`from:`クエリを使用

## 🔔 アラーム機能

音声コマンドまたは設定画面から、時刻を指定してアラームを設定できます。

### 機能の特徴

- **音声設定**: 「明日の朝7時にアラームをセットして」で簡単設定
- **UI管理**: 設定画面の「アラーム」ツールから詳細管理
- **読み上げ機能**: 設定したメッセージを音声で再生
- **繰り返し対応**: 毎日繰り返すアラームの設定が可能
- **ベル音**: アラーム実行時にベル音→メッセージ読み上げの2段階通知

### 使用方法

1. **音声で設定**: 「〇時にアラームセットして」と話しかける
2. **UI で設定**: 設定画面 → 「アラーム」ツールクリック → 時刻・メッセージ入力
3. **一覧確認**: 設定済みアラームを確認・削除可能

## 📷 カメラ画像認識機能

OpenAI Vision APIを使用して、カメラで撮影した画像を自動分析します。

### 機能の特徴

- **WebRTCカメラアクセス**: ブラウザから直接カメラを起動
- **画像分析**: GPT-4o Visionで画像内容を詳細に説明
- **音声読み上げ**: 分析結果をTTSで自動読み上げ
- **モバイル対応**: 背面カメラを優先的に使用

### 使用方法

1. **カメラ起動**: 音声入力画像の左下にある「カメラ」ボタンをクリック
2. **カメラ許可**: ブラウザのカメラアクセス許可を承認
3. **撮影・分析**: 「📸 撮影して分析」ボタンをクリック
4. **結果確認**: 画像の内容が文字と音声で返される

### 設定

Vision APIを使用するには、`.env`にOpenAI APIキーが必要です：

```bash
OPENAI_API_KEY=your_openai_api_key
```

## 🤖 AIモード機能

ユーザーのニーズに応じて、AIの動作モードを切り替えることができます。

### モードの種類

#### **📋 スタンダードモード**（デフォルト）
- ユーザーの明示的な指示に従ってツールを使用
- 指示がない場合は、情報を提供したり質問に答える
- 必要に応じて、ツールの使用を提案することも可能

**使用例:**
- ユーザー: 「メールを確認して」 → AIがGmailツールを実行
- ユーザー: 「おはよう」 → 挨拶のみ（ツール実行なし）

#### **🔥 全自動モード**
- ユーザーの明示的な指示がなくても、会話の文脈から意図を推測
- 必要なツールを積極的に使用してプロアクティブに行動
- 実行したアクションはテーブルに自動記録

**使用例:**
- ユーザー: 「おはよう」 → 未読メールチェック、天気情報取得、今日の予定確認
- ユーザー: 「忙しい」 → 今日の重要なタスク確認、リマインダー設定
- 時間帯や文脈に応じた自動アクション

### テーブル機能

全自動モードで実行されたタスクは、設定画面の「📊 テーブル」セクションに自動的に記録されます。

**表示内容:**
- タスクのタイトル（ユーザー入力内容）
- 実行したツール名
- ステータス（処理中/完了）
- 実行結果のサマリー
- 実行日時

### モード切り替え方法

1. 画面右上のハンバーガーメニュー（☰）をクリック
2. 「🎯 AIモード設定」セクションでモードを選択
3. 「適用」ボタンをクリック

## 🧠 性格タイプ分析機能

会話履歴を分析して、ユーザーの性格タイプを自動的に判定・可視化します。

### 性格タイプの種類

- **😊 社交的タイプ** - フレンドリー、協調性、共感力
- **🤔 分析的タイプ** - 論理的思考、問題解決能力、洞察力
- **🎨 創造的タイプ** - 創造性、想像力、表現力
- **⚙️ 実用的タイプ** - 効率性、実用性、現実的
- **🔍 探究的タイプ** - 好奇心、学習意欲、探究心
- **🌙 穏やかタイプ** - 落ち着き、思慮深さ、内省的

### 機能の特徴

- **自動分析**: 会話データから6つの性格特性をキーワード解析
- **信頼度表示**: 会話データの量に基づいて信頼度を0〜100%で表示
- **リアルタイム更新**: 設定画面を開くたびに最新の分析結果を表示
- **視覚的表現**: アイコン、説明、特性バッジ、信頼度バーで分かりやすく表示

### アクセス方法

1. 画面右上のハンバーガーメニュー（☰）をクリック
2. 設定画面が開き、「あなたの性格タイプ」セクションが自動表示
3. 🔄ボタンで再分析可能

## 🔧 カスタマイズ

### 新しいツールの追加

`src/tools/` にツールクラスを追加：

```python
from src.core.tool_base import Tool

class WeatherTool(Tool):
    name = "weather"
    description = "天気情報を取得"

    async def execute(self, params: dict) -> str:
        # 実装
        return result
```

### ルールの追加

`src/core/rule_processor.py`にルールを追加：

```python
{
    "name": "custom_rule",
    "patterns": [r"カスタム.*パターン"],
    "responses": ["カスタム応答"],
    "priority": 10
}
```

## 🚀 デプロイ

### Vercel（推奨）

クラウドでの簡単デプロイ：

1. **環境変数の設定**
   ```bash
   OPENAI_API_KEY=your_openai_api_key
   ANTHROPIC_API_KEY=your_anthropic_api_key
   ```

2. **デプロイ実行**
   ```bash
   # GitHubリポジトリをVercelに接続
   # 自動デプロイが開始されます
   ```

3. **利用可能な機能**
   - ✅ REST API チャット
   - ✅ LLM対話（Claude、OpenAI）
   - ✅ 基本ツール機能
   - ❌ WebSocket音声（サーバーレス制限）

📚 **詳細**: [VERCEL_DEPLOYMENT.md](./VERCEL_DEPLOYMENT.md) を参照

### Docker Compose

ローカル・VPS デプロイ：

```yaml
# docker-compose.yml
version: '3.8'
services:
  voiceagent:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://...
```

## 📊 モニタリング

- ログ: `data/voiceagent.log`
- ダッシュボード: `http://localhost:8000/dashboard`
- API文書: `http://localhost:8000/docs`

## 🤝 コントリビュート

1. フォーク
2. フィーチャーブランチ作成
3. コミット
4. プルリクエスト

## 📄 ライセンス

MIT License