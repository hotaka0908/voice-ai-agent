#!/usr/bin/env python3
"""
Fixed LLM Test - ä¿®æ­£æ¸ˆã¿LLMãƒ†ã‚¹ãƒˆ

ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã‚’æ˜ç¤ºçš„ã«è¡Œã†LLMãƒ†ã‚¹ãƒˆ
"""

import asyncio
import sys
import os
from datetime import datetime
from loguru import logger
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(__file__))

# ç’°å¢ƒå¤‰æ•°ã‚’æ˜ç¤ºçš„ã«èª­ã¿è¾¼ã¿
load_dotenv()

from src.llm.hybrid_llm import HybridLLM
from src.tools.tool_registry import ToolRegistry
from src.memory.personal_memory import PersonalMemory
from src.core.context_manager import ContextManager


async def test_llm_with_env():
    """ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ã‚’æ˜ç¤ºçš„ã«è¡Œã†LLMãƒ†ã‚¹ãƒˆ"""

    print("ğŸ‰ ä¿®æ­£æ¸ˆã¿LLMãƒ†ã‚¹ãƒˆ")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´
    logger.remove()
    logger.add(sys.stderr, level="INFO")

    # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
    print("ğŸ”‘ ç’°å¢ƒå¤‰æ•°ç¢ºèª:")
    openai_key = os.getenv("OPENAI_API_KEY")
    anthropic_key = os.getenv("ANTHROPIC_API_KEY")

    print(f"   OpenAI API Key: {'âœ… è¨­å®šæ¸ˆã¿ (%dæ–‡å­—)' % len(openai_key) if openai_key else 'âŒ æœªè¨­å®š'}")
    print(f"   Anthropic API Key: {'âœ… è¨­å®šæ¸ˆã¿ (%dæ–‡å­—)' % len(anthropic_key) if anthropic_key else 'âŒ æœªè¨­å®š'}")

    llm = None
    tools = None
    memory = None
    context = None

    try:
        # ===== 1. å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ– =====
        print("\nğŸ”§ 1. å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–")
        print("-" * 30)

        # ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ 
        print("   ğŸ§  ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        memory = PersonalMemory()
        await memory.initialize()
        print("   âœ… ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

        # ãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ 
        print("   ğŸ”§ ãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        tools = ToolRegistry()
        await tools.initialize()
        available_tools = tools.get_available_tools()
        print(f"   âœ… ãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº† ({len(available_tools)}å€‹ã®ãƒ„ãƒ¼ãƒ«)")

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
        print("   ğŸ’¬ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        context = ContextManager()
        await context.initialize()
        print("   âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

        # ===== 2. LLMã‚·ã‚¹ãƒ†ãƒ æ‰‹å‹•åˆæœŸåŒ– =====
        print("\nğŸ§  2. LLMã‚·ã‚¹ãƒ†ãƒ æ‰‹å‹•åˆæœŸåŒ–")
        print("-" * 30)

        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ©ç”¨å¯èƒ½æ€§ã®ç¢ºèª
        import importlib

        # Anthropicåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        try:
            anthropic_lib = importlib.import_module('anthropic')
            anthropic_available = bool(anthropic_key)
            print(f"   Anthropic: {'âœ… åˆ©ç”¨å¯èƒ½' if anthropic_available else 'âŒ åˆ©ç”¨ä¸å¯'}")
        except ImportError:
            anthropic_available = False
            print("   Anthropic: âŒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

        # OpenAIåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        try:
            openai_lib = importlib.import_module('openai')
            openai_available = bool(openai_key)
            print(f"   OpenAI: {'âœ… åˆ©ç”¨å¯èƒ½' if openai_available else 'âŒ åˆ©ç”¨ä¸å¯'}")
        except ImportError:
            openai_available = False
            print("   OpenAI: âŒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

        # ===== 3. ç›´æ¥APIå‘¼ã³å‡ºã—ãƒ†ã‚¹ãƒˆ =====
        if anthropic_available or openai_available:
            print("\nğŸ¤– 3. ç›´æ¥APIå‘¼ã³å‡ºã—ãƒ†ã‚¹ãƒˆ")
            print("-" * 30)

            # ã‚µãƒ³ãƒ—ãƒ«è³ªå•
            test_queries = [
                "ã“ã‚“ã«ã¡ã¯ï¼ç°¡æ½”ã«æŒ¨æ‹¶ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚",
                "2+2ã®ç­”ãˆã‚’æ•™ãˆã¦ã€‚",
                "ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚çŸ­ãã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚"
            ]

            for i, query in enumerate(test_queries, 1):
                print(f"\n   {i}. ãƒ†ã‚¹ãƒˆè³ªå•: {query}")

                if anthropic_available:
                    print("      ğŸ”µ Anthropic Claude ã§è©¦è¡Œ...")
                    try:
                        import anthropic
                        client = anthropic.Anthropic(api_key=anthropic_key)

                        response = client.messages.create(
                            model="claude-3-haiku-20240307",
                            max_tokens=50,
                            messages=[{"role": "user", "content": query}]
                        )

                        answer = response.content[0].text
                        print(f"      âœ… Claudeå¿œç­”: {answer}")

                        # ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
                        if memory:
                            await memory.store_interaction(query, answer)

                        # æˆåŠŸã—ãŸã‚‰OpenAIã¯ã‚¹ã‚­ãƒƒãƒ—
                        continue

                    except Exception as e:
                        print(f"      âŒ Claude ã‚¨ãƒ©ãƒ¼: {e}")

                if openai_available:
                    print("      ğŸŸ¢ OpenAI GPT ã§è©¦è¡Œ...")
                    try:
                        import openai
                        client = openai.OpenAI(api_key=openai_key)

                        response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[{"role": "user", "content": query}],
                            max_tokens=50
                        )

                        answer = response.choices[0].message.content
                        print(f"      âœ… GPTå¿œç­”: {answer}")

                        # ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
                        if memory:
                            await memory.store_interaction(query, answer)

                    except Exception as e:
                        print(f"      âŒ GPT ã‚¨ãƒ©ãƒ¼: {e}")

            # ===== 4. ãƒ„ãƒ¼ãƒ«é€£æºãƒ†ã‚¹ãƒˆ =====
            print("\nğŸ”§ 4. ãƒ„ãƒ¼ãƒ«é€£æºãƒ†ã‚¹ãƒˆ")
            print("-" * 30)

            print("   â° æ™‚åˆ»ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ:")
            time_result = await tools.execute_tool("time", {
                "timezone": "Asia/Tokyo",
                "format": "datetime"
            })
            print(f"   çµæœ: {time_result}")

            print("   ğŸ§® è¨ˆç®—ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ:")
            calc_result = await tools.execute_tool("calculator", {
                "expression": "10 * 3 + 7"
            })
            print(f"   çµæœ: {calc_result}")

            # ===== 5. ãƒ¡ãƒ¢ãƒªçµ±è¨ˆ =====
            print("\nğŸ§  5. ãƒ¡ãƒ¢ãƒªçµ±è¨ˆ")
            print("-" * 30)

            memory_status = await memory.get_status()
            print(f"   è¨˜æ†¶ã‚¨ãƒ³ãƒˆãƒªæ•°: {memory_status.get('memory_count', 0)}")
            print(f"   ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—: {memory_status.get('storage_type', 'ä¸æ˜')}")

            # æœ€è¿‘ã®ä¼šè©±ã‚’æ¤œç´¢
            recent_memories = await memory.search_relevant("ã“ã‚“ã«ã¡ã¯", limit=3)
            print(f"   é–¢é€£è¨˜æ†¶æ¤œç´¢çµæœ: {len(recent_memories)}ä»¶")

            print("\nğŸ‰ ä¿®æ­£æ¸ˆã¿ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            print("ğŸ’¡ APIã‚­ãƒ¼ã¯æ­£å¸¸ã«å‹•ä½œã—ã€åŸºæœ¬æ©Ÿèƒ½ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚")

        else:
            print("\nâŒ åˆ©ç”¨å¯èƒ½ãªLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")

    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        print("\nğŸ§¹ ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")

        cleanup_tasks = []
        if tools:
            cleanup_tasks.append(tools.cleanup())
        if memory:
            cleanup_tasks.append(memory.cleanup())

        if cleanup_tasks:
            await asyncio.gather(*cleanup_tasks, return_exceptions=True)

        print("âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        print(f"ğŸ ä¿®æ­£æ¸ˆã¿ãƒ†ã‚¹ãƒˆçµ‚äº†: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    asyncio.run(test_llm_with_env())